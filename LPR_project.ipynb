{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d88e2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell 1: Paths & Helper Functions\n",
    "# Set up paths and import required libraries\n",
    "# %% 1 · PATHS & HELPERS\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"   # allow duplicate OpenMP runtimes\n",
    "from pathlib import Path\n",
    "import pandas as pd, shutil, cv2, numpy as np, random, json\n",
    "from tqdm import tqdm\n",
    "\n",
    "ROOT = Path(r\"C:/Users/BHARATH SHIVA/Downloads/lpr_project\")\n",
    "\n",
    "TRAIN1_IMG_DIR = ROOT/\"train1_images\"\n",
    "TRAIN2_IMG_DIR = ROOT/\"train2_images\"\n",
    "TEST_IMG_DIR   = ROOT/\"test_images\"\n",
    "\n",
    "# pick the first file that matches either extension\n",
    "TRAIN1_CSV = next((ROOT/f for f in [\"train1_labels.csv\",\"train1_labels.xlsx\"] if (ROOT/f).exists()))\n",
    "TRAIN2_CSV = next((ROOT/f for f in [\"train2_labels.csv\",\"train2_labels.xlsx\"] if (ROOT/f).exists()))\n",
    "\n",
    "YOLO_DIR = ROOT/\"yolo_dataset\"\n",
    "OCR_DIR  = ROOT/\"ocr_dataset\"\n",
    "PRED_CSV = ROOT/\"test_predictions.csv\"\n",
    "\n",
    "YOLO_DIR.mkdir(parents=True, exist_ok=True)\n",
    "(OCR_DIR/\"images\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def read_table(path: Path) -> pd.DataFrame:\n",
    "    return pd.read_excel(path) if path.suffix==\".xlsx\" else pd.read_csv(path)\n",
    "\n",
    "print(\"Paths OK\")\n",
    "\n",
    "\n",
    "# %% 1‑B · QUICK SANITY‑CHECK\n",
    "for tag, p in [(\"train1\", TRAIN1_IMG_DIR),\n",
    "               (\"train2\", TRAIN2_IMG_DIR),\n",
    "               (\"test\",   TEST_IMG_DIR),\n",
    "               (\"det_lbl\",TRAIN1_CSV),\n",
    "               (\"ocr_lbl\",TRAIN2_CSV)]:\n",
    "    print(f\"{tag:<8} →\", \"OK\" if p.exists() else \"NOT FOUND\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893da474",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell 2: Sanity Check – Verify Input Files\n",
    "# Quick check to ensure all required paths and files exist\n",
    "# %% 2 · CONVERT train1_labels → YOLO TXT\n",
    "df_det = read_table(TRAIN1_CSV)  # must have: filename,ymin,xmin,ymax,xmax\n",
    "if not {\"filename\",\"ymin\",\"xmin\",\"ymax\",\"xmax\"}.issubset(df_det.columns):\n",
    "    raise ValueError(\"train1_labels missing required columns\")\n",
    "\n",
    "for p in [\"images/train\",\"images/val\",\"labels/train\",\"labels/val\"]:\n",
    "    (YOLO_DIR/p).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def to_yolo(size, box):\n",
    "    h,w = size\n",
    "    y1,x1,y2,x2 = box\n",
    "    return [0, (x1+x2)/2/w, (y1+y2)/2/h, (x2-x1)/w, (y2-y1)/h]\n",
    "\n",
    "val_ratio = 0.1\n",
    "val_set = set(random.sample(list(df_det.filename.unique()),\n",
    "                            int(len(df_det)*val_ratio)))\n",
    "\n",
    "for _,r in tqdm(df_det.iterrows(), total=len(df_det)):\n",
    "    src = TRAIN1_IMG_DIR/r.filename\n",
    "    if not src.exists(): continue\n",
    "    im = cv2.imread(str(src)); h,w = im.shape[:2]\n",
    "    yolo_line = \" \".join(map(str, to_yolo((h,w), r[[\"ymin\",\"xmin\",\"ymax\",\"xmax\"]])))\n",
    "    split = \"val\" if r.filename in val_set else \"train\"\n",
    "    shutil.copy(src, YOLO_DIR/f\"images/{split}\"/r.filename)\n",
    "    with open(YOLO_DIR/f\"labels/{split}\"/(src.stem+\".txt\"),\"w\") as f:\n",
    "        f.write(yolo_line+\"\\n\")\n",
    "\n",
    "(YOLO_DIR/\"data.yaml\").write_text(json.dumps({\n",
    "    \"path\": str(YOLO_DIR),\n",
    "    \"train\":\"images/train\",\n",
    "    \"val\":\"images/val\",\n",
    "    \"nc\":1,\n",
    "    \"names\":{0:\"license_plate\"}}, indent=2))\n",
    "print(\"✔ YOLO data prepared\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0bc57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell 3: Convert Detection Labels to YOLO Format\n",
    "# Load detection labels for YOLO (bounding boxes)\n",
    "# %% 3 · LIGHT‑WEIGHT YOLO‑v8 DETECTOR TRAIN\n",
    "from ultralytics import YOLO, checks\n",
    "from pathlib import Path\n",
    "checks()  # prints system info\n",
    "\n",
    "detector = YOLO(\"yolov8n.pt\")  # nano weights\n",
    "\n",
    "detector.train(\n",
    "    data    = str(YOLO_DIR / \"data.yaml\"),\n",
    "    epochs  = 15,          # reduce epochs for quick run\n",
    "    imgsz   = 416,         # smaller resolution\n",
    "    batch   = 4,           # small batch fits RAM\n",
    "    workers = 0,           # Windows: avoid multi‑proc crashes\n",
    "    freeze  = 10,          # train only detection head\n",
    "    plots   = False,       # skip heavy visualizations\n",
    "    name    = \"lp_det_safe\"\n",
    ")\n",
    "\n",
    "best_det = Path(detector.trainer.save_dir) / \"best.pt\"\n",
    "print(\"✔ Detector trained:\", best_det)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d44afb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Train YOLOv8 Detection Model\n",
    "# Train YOLOv8 on detection dataset\n",
    "# %% 4 · PREP OCR DATASET & TRAIN CRNN  (fixed height‑pool bug)\n",
    "import shutil, cv2, numpy as np, torch, torch.nn as nn, torchvision.transforms as T\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ---------- A · load labels & copy images ----------\n",
    "df_ocr = read_table(TRAIN2_CSV)\n",
    "if \"img_id\" not in df_ocr.columns:\n",
    "    df_ocr.columns = [\"img_id\", \"text\"]\n",
    "\n",
    "(OCR_DIR/\"images\").mkdir(parents=True, exist_ok=True)\n",
    "for f in tqdm(df_ocr.img_id.unique(), desc=\"copy ocr imgs\"):\n",
    "    src, dst = TRAIN2_IMG_DIR/f, OCR_DIR/\"images\"/f\n",
    "    if not dst.exists(): shutil.copy(src, dst)\n",
    "print(\"✅ OCR dataset ready:\", len(df_ocr))\n",
    "\n",
    "# ---------- B · dataset ----------\n",
    "CHARS = \"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "c2i = {c:i+1 for i,c in enumerate(CHARS)} ; i2c={i+1:c for i,c in enumerate(CHARS)}\n",
    "def enc(t): return [c2i[c] for c in t]\n",
    "\n",
    "tfm = T.Compose([\n",
    "    T.ToPILImage(),\n",
    "    T.Resize((32,128)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.5],[0.5])\n",
    "])\n",
    "\n",
    "class PlateDS(Dataset):\n",
    "    def __init__(s, df, root): s.df, s.root = df, root\n",
    "    def __len__(s): return len(s.df)\n",
    "    def __getitem__(s,i):\n",
    "        r=s.df.iloc[i]\n",
    "        img=cv2.imread(str(s.root/\"images\"/r.img_id),0)\n",
    "        return tfm(img), torch.tensor(enc(r.text)), len(r.text)\n",
    "\n",
    "def col(batch):\n",
    "    imgs,lbls,ll = zip(*batch)\n",
    "    imgs = torch.stack(imgs)\n",
    "    lbls = torch.cat(lbls)\n",
    "    ll   = torch.tensor(ll)\n",
    "    tl   = torch.full((len(batch),), imgs.size(3)//4, dtype=torch.long)\n",
    "    return imgs, lbls, tl, ll\n",
    "\n",
    "mask = np.random.rand(len(df_ocr))<0.1\n",
    "train_dl = DataLoader(PlateDS(df_ocr[~mask], OCR_DIR),64,True,collate_fn=col)\n",
    "val_dl   = DataLoader(PlateDS(df_ocr[mask],  OCR_DIR),64,False,collate_fn=col)\n",
    "\n",
    "# ---------- C · CRNN ----------\n",
    "class CRNN(nn.Module):\n",
    "    def __init__(self, n):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(1,64,3,1,1), nn.ReLU(), nn.MaxPool2d(2,2),\n",
    "            nn.Conv2d(64,128,3,1,1), nn.ReLU(), nn.MaxPool2d(2,2),\n",
    "            nn.Conv2d(128,256,3,1,1), nn.ReLU(), nn.MaxPool2d((2,1)),\n",
    "            nn.Conv2d(256,256,3,1,1), nn.ReLU(), nn.MaxPool2d((2,1))\n",
    "        )\n",
    "        self.rnn = nn.LSTM(256,256,2,batch_first=True,bidirectional=True)\n",
    "        self.fc  = nn.Linear(512,n+1)\n",
    "    def forward(self,x):\n",
    "        x = self.cnn(x)                        # [B,256,H=2,W]\n",
    "        x = F.adaptive_avg_pool2d(x,(1,None))  # [B,256,1,W]\n",
    "        x = x.squeeze(2)                       # [B,256,W]\n",
    "        x = x.permute(0,2,1)                   # [B,W,256]\n",
    "        x, _ = self.rnn(x)                     # [B,W,512]\n",
    "        return self.fc(x).log_softmax(2)\n",
    "\n",
    "device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "ocr   = CRNN(len(CHARS)).to(device)\n",
    "ctc   = nn.CTCLoss(blank=0, zero_infinity=True)\n",
    "opt   = torch.optim.AdamW(ocr.parameters(),1e-3)\n",
    "\n",
    "# ---------- D · train ----------\n",
    "EPOCHS=15\n",
    "for e in range(EPOCHS):\n",
    "    ocr.train(); tot=0\n",
    "    for imgs,lbls,tl,ll in train_dl:\n",
    "        imgs = imgs.to(device)\n",
    "        opt.zero_grad()\n",
    "        loss = ctc(ocr(imgs).permute(1,0,2), lbls, tl, ll)\n",
    "        loss.backward(); opt.step()\n",
    "        tot += loss.item()\n",
    "    print(f\"Epoch {e+1}/{EPOCHS}  loss={tot/len(train_dl):.4f}\")\n",
    "\n",
    "torch.save(ocr.state_dict(), ROOT/\"crnn_lp.pth\")\n",
    "print(\"✔ CRNN trained →\", ROOT/\"crnn_lp.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4ccfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell 5: Prepare OCR Dataset and Train CRNN Model\n",
    "# OCR training: prepare dataset and train CRNN\n",
    "# %% 5 · FAST INFERENCE (DETECT + OCR) ON test_images\n",
    "from pathlib import Path\n",
    "import glob, os, cv2, pandas as pd, torch\n",
    "from ultralytics import YOLO\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ---------- 5‑A · choose detector weights ----------\n",
    "run_ckpts = glob.glob(str(ROOT / \"runs/detect/*/*.pt\"))\n",
    "best_pt   = [p for p in run_ckpts if p.endswith(\"best.pt\")]\n",
    "last_pt   = [p for p in run_ckpts if p.endswith(\"last.pt\")]\n",
    "\n",
    "if best_pt:\n",
    "    det_wt = max(best_pt, key=os.path.getmtime)\n",
    "    print(\"Using best.pt:\", det_wt)\n",
    "elif last_pt:\n",
    "    det_wt = max(last_pt, key=os.path.getmtime)\n",
    "    print(\"best.pt not found; using last.pt:\", det_wt)\n",
    "else:\n",
    "    det_wt = \"yolov8n.pt\"\n",
    "    print(\"No run checkpoints found; falling back to yolov8n.pt (pretrained)\")\n",
    "\n",
    "# ---------- 5‑B · EasyOCR (primary OCR) ----------\n",
    "try:\n",
    "    import easyocr\n",
    "    reader = easyocr.Reader([\"en\"], gpu=torch.cuda.is_available())\n",
    "    print(\"easyocr loaded – will use as primary OCR\")\n",
    "except ModuleNotFoundError:\n",
    "    reader = None\n",
    "    print(\"easyocr not installed – CRNN only\")\n",
    "\n",
    "# ---------- 5‑C · load CRNN weights ----------\n",
    "ocr = CRNN(len(CHARS)).to(device)\n",
    "crnn_path = ROOT / \"crnn_lp.pth\"\n",
    "if crnn_path.exists():\n",
    "    ocr.load_state_dict(torch.load(crnn_path, map_location=device))\n",
    "    print(\"CRNN weights loaded:\", crnn_path.name)\n",
    "else:\n",
    "    print(\"CRNN weights not found – will output blank if EasyOCR fails\")\n",
    "ocr.eval()\n",
    "\n",
    "# ---------- 5‑D · detector & transforms ----------\n",
    "det = YOLO(det_wt)\n",
    "det.overrides[\"imgsz\"] = 416            # smaller input → faster\n",
    "\n",
    "tf = T.Compose([\n",
    "    T.ToPILImage(),\n",
    "    T.Resize((32, 128)),                # match CRNN training size\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "def decode_crnn(img_bgr):\n",
    "    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    tensor = tf(gray).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        pred = ocr(tensor).permute(1, 0, 2).softmax(2).argmax(2).squeeze().cpu().numpy()\n",
    "    txt, prev = \"\", -1\n",
    "    for p in pred:\n",
    "        if p != prev and p != 0:\n",
    "            txt += i2c[p]\n",
    "        prev = p\n",
    "    return txt\n",
    "\n",
    "# ---------- 5‑E · run batch inference ----------\n",
    "rows = []\n",
    "results = det.predict(\n",
    "    source = str(TEST_IMG_DIR),        # folder of 201 images\n",
    "    stream = True,                     # generator\n",
    "    imgsz  = 416,\n",
    "    verbose = False\n",
    ")\n",
    "\n",
    "total_imgs = len(list(TEST_IMG_DIR.glob(\"*.jpg\")))\n",
    "for r in tqdm(results, total=total_imgs, desc=\"inferring\"):\n",
    "    img_path = Path(r.path)\n",
    "    if len(r.boxes) == 0:\n",
    "        continue\n",
    "    i = r.boxes.conf.argmax()\n",
    "    xmin, ymin, xmax, ymax = map(int, r.boxes.xyxy[i].cpu())\n",
    "    crop = r.orig_img[ymin:ymax, xmin:xmax]how to download the .ipynb and\n",
    "\n",
    "    # ---- OCR pipeline ----\n",
    "    plate_txt = \"\".join(reader.readtext(crop, detail=0)) if reader else \"\"\n",
    "    if plate_txt == \"\":\n",
    "        plate_txt = decode_crnn(crop)\n",
    "\n",
    "    rows.append(dict(\n",
    "        image_name = img_path.name,\n",
    "        ymin = ymin, xmin = xmin,\n",
    "        ymax = ymax, xmax = xmax,\n",
    "        plate_text = plate_txt\n",
    "    ))\n",
    "\n",
    "out_df = pd.DataFrame(rows)\n",
    "import csv\n",
    "out_df.to_csv(PRED_CSV, index=False, quoting=csv.QUOTE_ALL, encoding=\"utf-8\")\n",
    "print(f\"✅ Predictions saved → {PRED_CSV}\")\n",
    "display(out_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcaa40b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
